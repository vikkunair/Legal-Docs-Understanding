{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependency import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dataset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: './finetune_squad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/Users/vikkunair/Documents/Contract_Obligation_Tests/structure_data.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/vikkunair/Documents/Contract_Obligation_Tests/structure_data.ipynb#ch0000003?line=0'>1</a>\u001b[0m os\u001b[39m.\u001b[39;49mmkdir(\u001b[39m\"\u001b[39;49m\u001b[39m./finetune_squad\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: './finetune_squad'"
     ]
    }
   ],
   "source": [
    "os.mkdir(\"./finetune_squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://rajpurkar.github.io/SQuAD-explorer/dataset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_key = ['train-v2.0.json','dev-v2.0.json']\n",
    "\n",
    "for key in train_test_key:\n",
    "    response = requests.get(f'{link}{key}')\n",
    "    with open (f'finetune_squad/{key}','wb') as file:\n",
    "        for small_chunk in response.iter_content(chunk_size=10):\n",
    "            file.write(small_chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data(path):\n",
    "    contexts = []\n",
    "    answers = []\n",
    "    questions = []\n",
    "    with open(path) as file:\n",
    "        json_data = json.load(file)\n",
    "        for item in json_data['data']:\n",
    "            paragraph = item['paragraphs']\n",
    "            for sub_item in paragraph:\n",
    "                context = sub_item['context']\n",
    "                for qas in sub_item['qas']:\n",
    "                    question = qas['question']\n",
    "\n",
    "                    if 'plausible_answers' not in qas.keys():\n",
    "                        answer = qas['answers'][0]\n",
    "                    else:\n",
    "                        try:\n",
    "                            answer = qas['plausible_answers'][0]\n",
    "                        except:\n",
    "                            continue\n",
    "                    \n",
    "                    contexts.append(context)\n",
    "                    answers.append(answer)\n",
    "                    questions.append(question)\n",
    "    return contexts,answers,questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'finetune_squad/train-v2.0.json'\n",
    "test_path = 'finetune_squad/dev-v2.0.json'\n",
    "\n",
    "train_contexts,train_answers,train_questions = get_train_test_data(train_path)\n",
    "test_contexts,test_answers,test_questions = get_train_test_data(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding end index for SQUAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_end_index(answers,contexts):\n",
    "    for answer, context in zip(answers,contexts):\n",
    "        answer_text = answer['text']\n",
    "        starting_index = answer['answer_start']\n",
    "        ending_index = starting_index + len(answer_text)\n",
    "\n",
    "        if context[starting_index:ending_index] == answer_text:\n",
    "            answer['answer_end'] = ending_index\n",
    "\n",
    "        else:\n",
    "            for shift in [1,2]:\n",
    "                if context[starting_index-shift:ending_index-shift] == answer_text:\n",
    "                    answer['answer_start'] = starting_index-shift\n",
    "                    answer['answer_end'] = ending_index-shift\n",
    "\n",
    "add_end_index(train_answers,train_contexts)\n",
    "add_end_index(test_answers,test_contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding/ Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_contexts,train_questions,truncation=True,padding=True)\n",
    "test_encodings = tokenizer(test_contexts,test_questions,truncation=True,padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] beyonce giselle knowles - carter ( / biːˈjɒnseɪ / bee - yon - say ) ( born september 4, 1981 ) is an american singer, songwriter, record producer and actress. born and raised in houston, texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of r & b girl - group destiny\\'s child. managed by her father, mathew knowles, the group became one of the world\\'s best - selling girl groups of all time. their hiatus saw the release of beyonce\\'s debut album, dangerously in love ( 2003 ), which established her as a solo artist worldwide, earned five grammy awards and featured the billboard hot 100 number - one singles \" crazy in love \" and \" baby boy \". [SEP] when did beyonce start becoming popular? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(train_encodings['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1999"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings['input_ids'][0][67]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings.char_to_token(0,train_answers[0]['answer_end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'in the late 1990s', 'answer_start': 269, 'answer_end': 286}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_answers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_tokens(encodings,answers):\n",
    "    start_pos = []\n",
    "    end_pos = []\n",
    "    for i in range(len(answers)):\n",
    "        start_pos.append(encodings.char_to_token(i,answers[i]['answer_start']))\n",
    "        end_pos.append(encodings.char_to_token(i,answers[i]['answer_end']))\n",
    "\n",
    "        if start_pos[-1] is None:\n",
    "            start_pos[-1] = tokenizer.model_max_length\n",
    "        \n",
    "        back = 1\n",
    "        while end_pos[-1] is None:\n",
    "            end_pos[-1] = encodings.char_to_token(i,answers[i]['answer_end']-back)\n",
    "\n",
    "            back += 1 \n",
    "\n",
    "        encodings.update({\"start_pos\":start_pos,\"end_pos\":end_pos})\n",
    "\n",
    "get_answer_tokens(train_encodings,train_answers)\n",
    "get_answer_tokens(test_encodings,test_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class sqdat(torch.utils.data.Dataset):\n",
    "    def __init__(self,encodings):\n",
    "        self.encodings = encodings\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return {key:torch.tensor(val[idx]) for key,val, in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "\n",
    "train_datasets = sqdat(train_encodings)\n",
    "\n",
    "\n",
    "test_datasets = sqdat(test_encodings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine Tuning using a transformers model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 256M/256M [00:19<00:00, 13.5MB/s] \n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForQuestionAnswering\n",
    "\n",
    "model = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vikkunair/.local/share/virtualenvs/Contract_Obligation_Tests-5AjLZ1i5/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "model.train()\n",
    "optim = AdamW(model.parameters(), lr = 5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   1%|          | 85/16290 [05:48<18:26:24,  4.10s/it, loss=3.73]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/vikkunair/Documents/Contract_Obligation_Tests/structure_data.ipynb Cell 26'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vikkunair/Documents/Contract_Obligation_Tests/structure_data.ipynb#ch0000025?line=17'>18</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(input_ids,attention_mask \u001b[39m=\u001b[39m attention_mask,start_positions \u001b[39m=\u001b[39m start_pos,end_positions \u001b[39m=\u001b[39m end_pos)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vikkunair/Documents/Contract_Obligation_Tests/structure_data.ipynb#ch0000025?line=20'>21</a>\u001b[0m loss \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/vikkunair/Documents/Contract_Obligation_Tests/structure_data.ipynb#ch0000025?line=22'>23</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vikkunair/Documents/Contract_Obligation_Tests/structure_data.ipynb#ch0000025?line=24'>25</a>\u001b[0m optim\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vikkunair/Documents/Contract_Obligation_Tests/structure_data.ipynb#ch0000025?line=27'>28</a>\u001b[0m loop\u001b[39m.\u001b[39mset_description(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Contract_Obligation_Tests-5AjLZ1i5/lib/python3.9/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/vikkunair/.local/share/virtualenvs/Contract_Obligation_Tests-5AjLZ1i5/lib/python3.9/site-packages/torch/_tensor.py?line=353'>354</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///Users/vikkunair/.local/share/virtualenvs/Contract_Obligation_Tests-5AjLZ1i5/lib/python3.9/site-packages/torch/_tensor.py?line=354'>355</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    <a href='file:///Users/vikkunair/.local/share/virtualenvs/Contract_Obligation_Tests-5AjLZ1i5/lib/python3.9/site-packages/torch/_tensor.py?line=355'>356</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    <a href='file:///Users/vikkunair/.local/share/virtualenvs/Contract_Obligation_Tests-5AjLZ1i5/lib/python3.9/site-packages/torch/_tensor.py?line=356'>357</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/vikkunair/.local/share/virtualenvs/Contract_Obligation_Tests-5AjLZ1i5/lib/python3.9/site-packages/torch/_tensor.py?line=360'>361</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    <a href='file:///Users/vikkunair/.local/share/virtualenvs/Contract_Obligation_Tests-5AjLZ1i5/lib/python3.9/site-packages/torch/_tensor.py?line=361'>362</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> <a href='file:///Users/vikkunair/.local/share/virtualenvs/Contract_Obligation_Tests-5AjLZ1i5/lib/python3.9/site-packages/torch/_tensor.py?line=362'>363</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Contract_Obligation_Tests-5AjLZ1i5/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/vikkunair/.local/share/virtualenvs/Contract_Obligation_Tests-5AjLZ1i5/lib/python3.9/site-packages/torch/autograd/__init__.py?line=167'>168</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    <a href='file:///Users/vikkunair/.local/share/virtualenvs/Contract_Obligation_Tests-5AjLZ1i5/lib/python3.9/site-packages/torch/autograd/__init__.py?line=169'>170</a>\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/vikkunair/.local/share/virtualenvs/Contract_Obligation_Tests-5AjLZ1i5/lib/python3.9/site-packages/torch/autograd/__init__.py?line=170'>171</a>\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/vikkunair/.local/share/virtualenvs/Contract_Obligation_Tests-5AjLZ1i5/lib/python3.9/site-packages/torch/autograd/__init__.py?line=171'>172</a>\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/vikkunair/.local/share/virtualenvs/Contract_Obligation_Tests-5AjLZ1i5/lib/python3.9/site-packages/torch/autograd/__init__.py?line=172'>173</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    <a href='file:///Users/vikkunair/.local/share/virtualenvs/Contract_Obligation_Tests-5AjLZ1i5/lib/python3.9/site-packages/torch/autograd/__init__.py?line=173'>174</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    <a href='file:///Users/vikkunair/.local/share/virtualenvs/Contract_Obligation_Tests-5AjLZ1i5/lib/python3.9/site-packages/torch/autograd/__init__.py?line=174'>175</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_datasets, batch_size=8,shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    loop = tqdm(train_loader)\n",
    "    for batch in loop:\n",
    "        optim.zero_grad()\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "        start_pos = batch['start_pos'].to(device)\n",
    "\n",
    "        end_pos = batch['end_pos'].to(device)\n",
    "\n",
    "        outputs = model(input_ids,attention_mask = attention_mask,start_positions = start_pos,end_positions = end_pos)\n",
    "        \n",
    "\n",
    "        loss = outputs[0]\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "\n",
    "        loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'model/distil_fine_tuned'\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_datasets)\n",
    "\n",
    "accuracy = []\n",
    "\n",
    "\n",
    "loop = tqdm(test_loader)\n",
    "for batch in loop:\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "        start_pos = batch['start_pos'].to(device)\n",
    "\n",
    "        end_pos = batch['end_pos'].to(device)\n",
    "\n",
    "        outputs = model(input_ids,attention_mask = attention_mask)\n",
    "\n",
    "        start_preds = torch.argmax(outputs['start_logits'],dim=1)\n",
    "        end_preds = torch.argmax(outputs['end_logits'],dim=1)\n",
    "\n",
    "        accuracy.append(((start_pos == start_preds).sum()/len(start_preds)).item())\n",
    "        accuracy.append(((end_pos == end_preds).sum()/len(end_preds)).item())\n",
    "# calculate average accuracy in total\n",
    "acc = sum(accuracy)/len(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(outputs['start_logits'], dim=1)\n",
    "torch.argmax(outputs['end_logits'], dim=1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "29ecdedd8fc18943b7ea835ef58409d3e8ec58d825973310b6c3ddb65deced6d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('Contract_Obligation_Tests-5AjLZ1i5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
